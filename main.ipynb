{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "load data\n",
    "\"\"\"\n",
    "%reload_ext autoreload\n",
    "import numpy as np\n",
    "import csvio\n",
    "import copy\n",
    "import random\n",
    "import data_processing as dp\n",
    "\n",
    "motions, headers = csvio.load_data('./input_data/train/train.csv')\n",
    "\n",
    "bow_motions = motions[0:11]\n",
    "wav_motions = motions[11:33]\n",
    "run_motions = motions[33:45] + motions[56:67]\n",
    "frt_motions = motions[45:56]\n",
    "wlk_motions = motions[67:91]\n",
    "bck_motions = motions[91:103]\n",
    "rgt_motions = motions[103:115]\n",
    "lft_motions = motions[115:127] \n",
    "\n",
    "model_settings = {\n",
    "    \"0_45_bow\": [45, 2, bow_motions, np.linspace(0.9, 1.1, 15)],\n",
    "    \"1_45_wav\": [45, 3, wav_motions, np.linspace(0.9, 1.1, 15)],\n",
    "    \"2_45_run\": [45, 1, run_motions, np.linspace(0.9, 1.1, 15)],\n",
    "    # \"3_45_frt\":  [45, 1, list(range(21)), frt_motions, np.linspace(0.8, 1.2, 15), None],\n",
    "    # \"4_45_wlk\":  [45, 3, list(range(21)), wlk_motions, np.linspace(0.8, 1.1, 25), None],\n",
    "    # \"6_45_rgt\":  [45, 1, list(range(21)), rgt_motions, np.linspace(0.9, 1.1, 25), None],\n",
    "\n",
    "    # \"0_15_bow\":  [15, 3, list(range(21)), run_motions, np.linspace(0.9, 1.1, 15), None],\n",
    "    # \"1_15_wavr\": [15, 3, list(range(21)), wavr_motions, np.linspace(0.9, 1.1, 15), None],\n",
    "    # \"2_15_run\": [15, 3, list(range(21)), run_motions, np.linspace(0.9, 1.1, 15), None],\n",
    "    # \"3_15_frt\": [15, 3, list(range(21)), frt_motions, np.linspace(0.9, 1.1, 15), None],\n",
    "    # \"4_15_wlk\": [15, 3, list(range(21)), wlk_motions, np.linspace(0.9, 1.1, 15), None],\n",
    "    # \"5_15_bck\": [15, 3, list(range(21)), bck_motions, np.linspace(0.9, 1.1, 15), None],\n",
    "    # \"6_15_rgt\": [15, 3, list(range(21)), rgt_motions, np.linspace(0.9, 1.1, 15), None],\n",
    "    # \"7_15_lft\": [15, 3, list(range(21)), lft_motions, np.linspace(0.9, 1.1, 15), None],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import interpolation\n",
    "from model import TransMotion\n",
    "import prediction as pred\n",
    "import graph\n",
    "import math\n",
    "import dataset\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "def train(source, target):\n",
    "    \"\"\"\n",
    "    source: (data_size, window, feature)\n",
    "    target: (data_size, window, feature)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    for _ in range(0, len(source) - batch_size, batch_size):\n",
    "        data, targets = dataset.get_both_batch(source, target, batch_size, input_window)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        if additional_loss:\n",
    "            exist_frames = list(range(0, input_window, interval))\n",
    "            loss = criterion(output, targets) + criterion(output[exist_frames], targets[exist_frames])\n",
    "        else:\n",
    "            loss = criterion(output, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(range(0, len(source) - 1, batch_size))\n",
    "\n",
    "\n",
    "def evaluate(eval_model, source, target):\n",
    "    eval_batch_size = min(64, len(source))\n",
    "    eval_model.eval()\n",
    "    with torch.no_grad():\n",
    "        src, tgt = dataset.get_both_batch(source, target, eval_batch_size, input_window)\n",
    "        out = eval_model(src)\n",
    "\n",
    "        index = random.randint(0, out.shape[2] - 1)\n",
    "        marker = index // 3\n",
    "        axis = index % 3\n",
    "        filename = f\"eval_{epoch}_{marker}_{axis}.png\"\n",
    "        graph.plot_name(src.cpu().detach().numpy()[:, 0, index],\n",
    "                   out.cpu().detach().numpy()[:, 0, index],\n",
    "                   tgt.cpu().detach().numpy()[:, 0, index],\n",
    "                   filename)\n",
    "\n",
    "        loss = criterion(out, tgt)\n",
    "\n",
    "    return loss.item()\n",
    "\n",
    "batch_size = 8\n",
    "device = torch.device(\"cuda\")\n",
    "additional_loss = False\n",
    "X, Y, Z = 0, 1, 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_motions: 20\n",
      "valid_motions: 3\n",
      "====== model/2_45_run_0.pth ======\n",
      "data: torch.Size([4395, 46, 63])\n",
      "data: torch.Size([1429, 46, 63])\n",
      "| epoch   1 | train loss 0.06163 | valid loss 0.02669 | lr 0.00500 | best\n",
      "| epoch   2 | train loss 0.03088 | valid loss 0.02466 | lr 0.00498 | best\n",
      "| epoch   3 | train loss 0.02824 | valid loss 0.02925 | lr 0.00495 |\n",
      "| epoch   4 | train loss 0.02613 | valid loss 0.02671 | lr 0.00493 |\n",
      "| epoch   5 | train loss 0.02436 | valid loss 0.03702 | lr 0.00490 |\n",
      "| epoch   6 | train loss 0.02431 | valid loss 0.02499 | lr 0.00488 |\n",
      "| epoch   7 | train loss 0.02196 | valid loss 0.02724 | lr 0.00485 |\n",
      "| epoch   8 | train loss 0.02194 | valid loss 0.02756 | lr 0.00483 |\n",
      "| epoch   9 | train loss 0.02162 | valid loss 0.03121 | lr 0.00480 |\n",
      "| epoch  10 | train loss 0.01967 | valid loss 0.03170 | lr 0.00478 |\n",
      "| epoch  11 | train loss 0.01971 | valid loss 0.02286 | lr 0.00476 | best\n",
      "| epoch  12 | train loss 0.02005 | valid loss 0.02602 | lr 0.00473 |\n",
      "| epoch  13 | train loss 0.01904 | valid loss 0.03186 | lr 0.00471 |\n",
      "| epoch  14 | train loss 0.01929 | valid loss 0.02849 | lr 0.00468 |\n",
      "| epoch  15 | train loss 0.01863 | valid loss 0.02532 | lr 0.00466 |\n",
      "| epoch  16 | train loss 0.01867 | valid loss 0.02593 | lr 0.00464 |\n",
      "| epoch  17 | train loss 0.01848 | valid loss 0.02283 | lr 0.00461 | best\n",
      "| epoch  18 | train loss 0.01784 | valid loss 0.02914 | lr 0.00459 |\n",
      "| epoch  19 | train loss 0.01768 | valid loss 0.02316 | lr 0.00457 |\n",
      "| epoch  20 | train loss 0.01699 | valid loss 0.02810 | lr 0.00455 |\n",
      "\n",
      "====== model/2_45_run_1.pth ======\n",
      "data: torch.Size([4395, 46, 63])\n",
      "data: torch.Size([1429, 46, 63])\n",
      "| epoch   1 | train loss 0.06032 | valid loss 0.03303 | lr 0.00500 | best\n",
      "| epoch   2 | train loss 0.03173 | valid loss 0.02245 | lr 0.00498 | best\n",
      "| epoch   3 | train loss 0.02790 | valid loss 0.02486 | lr 0.00495 |\n",
      "| epoch   4 | train loss 0.02613 | valid loss 0.02921 | lr 0.00493 |\n",
      "| epoch   5 | train loss 0.02410 | valid loss 0.02659 | lr 0.00490 |\n",
      "| epoch   6 | train loss 0.02230 | valid loss 0.02991 | lr 0.00488 |\n",
      "| epoch   7 | train loss 0.02285 | valid loss 0.02772 | lr 0.00485 |\n",
      "| epoch   8 | train loss 0.02156 | valid loss 0.02792 | lr 0.00483 |\n",
      "| epoch   9 | train loss 0.02084 | valid loss 0.02792 | lr 0.00480 |\n",
      "| epoch  10 | train loss 0.01993 | valid loss 0.02558 | lr 0.00478 |\n",
      "| epoch  11 | train loss 0.02010 | valid loss 0.02984 | lr 0.00476 |\n",
      "| epoch  12 | train loss 0.01917 | valid loss 0.02742 | lr 0.00473 |\n",
      "| epoch  13 | train loss 0.01886 | valid loss 0.03096 | lr 0.00471 |\n",
      "| epoch  14 | train loss 0.01871 | valid loss 0.02870 | lr 0.00468 |\n",
      "| epoch  15 | train loss 0.01919 | valid loss 0.02890 | lr 0.00466 |\n",
      "| epoch  16 | train loss 0.01812 | valid loss 0.02997 | lr 0.00464 |\n",
      "| epoch  17 | train loss 0.01819 | valid loss 0.03052 | lr 0.00461 |\n",
      "| epoch  18 | train loss 0.01829 | valid loss 0.02700 | lr 0.00459 |\n",
      "| epoch  19 | train loss 0.01759 | valid loss 0.03282 | lr 0.00457 |\n",
      "| epoch  20 | train loss 0.01758 | valid loss 0.02894 | lr 0.00455 |\n",
      "\n",
      "====== model/2_45_run_2.pth ======\n",
      "data: torch.Size([4395, 46, 63])\n",
      "data: torch.Size([1429, 46, 63])\n",
      "| epoch   1 | train loss 0.06144 | valid loss 0.02823 | lr 0.00500 | best\n",
      "| epoch   2 | train loss 0.03139 | valid loss 0.02589 | lr 0.00498 | best\n",
      "| epoch   3 | train loss 0.02701 | valid loss 0.02671 | lr 0.00495 |\n",
      "| epoch   4 | train loss 0.02593 | valid loss 0.03306 | lr 0.00493 |\n",
      "| epoch   5 | train loss 0.02507 | valid loss 0.02531 | lr 0.00490 | best\n",
      "| epoch   6 | train loss 0.02313 | valid loss 0.02653 | lr 0.00488 |\n",
      "| epoch   7 | train loss 0.02219 | valid loss 0.03274 | lr 0.00485 |\n",
      "| epoch   8 | train loss 0.02252 | valid loss 0.02306 | lr 0.00483 | best\n",
      "| epoch   9 | train loss 0.01999 | valid loss 0.02729 | lr 0.00480 |\n",
      "| epoch  10 | train loss 0.02082 | valid loss 0.03127 | lr 0.00478 |\n",
      "| epoch  11 | train loss 0.01949 | valid loss 0.02417 | lr 0.00476 |\n",
      "| epoch  12 | train loss 0.01994 | valid loss 0.02519 | lr 0.00473 |\n",
      "| epoch  13 | train loss 0.01956 | valid loss 0.03231 | lr 0.00471 |\n",
      "| epoch  14 | train loss 0.01925 | valid loss 0.02529 | lr 0.00468 |\n",
      "| epoch  15 | train loss 0.01859 | valid loss 0.02897 | lr 0.00466 |\n",
      "| epoch  16 | train loss 0.01858 | valid loss 0.03339 | lr 0.00464 |\n",
      "| epoch  17 | train loss 0.01880 | valid loss 0.03093 | lr 0.00461 |\n",
      "| epoch  18 | train loss 0.01831 | valid loss 0.02405 | lr 0.00459 |\n",
      "| epoch  19 | train loss 0.01851 | valid loss 0.02592 | lr 0.00457 |\n",
      "| epoch  20 | train loss 0.01883 | valid loss 0.02876 | lr 0.00455 |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in model_settings:\n",
    "    epochs = 20\n",
    "    interval, sections, motion_list, rates = model_settings[name]\n",
    "    input_window = interval * sections + 1\n",
    "    train_motions, valid_motions = dataset.get_train_valid(motion_list)\n",
    "\n",
    "    for model_num in range(3):\n",
    "        model_path = f\"model/{name}_{model_num}.pth\"\n",
    "\n",
    "        best_valid_loss = float(\"inf\")\n",
    "        model = TransMotion(interval, d_input=63).to(device).double()\n",
    "        lr = 0.005\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = torch.optim.RAdam(model.parameters(), lr=lr, weight_decay=0.00001)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.995)\n",
    "\n",
    "        print(f\"====== {model_path} ======\")\n",
    "        train_source, train_target = dataset.make_dataset(train_motions, interval, input_window, rates)\n",
    "        valid_source, valid_target = dataset.make_dataset(valid_motions, interval, input_window, rates)\n",
    "        train_loss_list = []\n",
    "        valid_loss_list = []\n",
    "        for epoch in range(1, epochs + 1):\n",
    "            train_loss = train(train_source, train_target)\n",
    "            valid_loss = evaluate(model, valid_source, valid_target)\n",
    "            train_loss_list.append(train_loss)\n",
    "            valid_loss_list.append(valid_loss)\n",
    "            if valid_loss < best_valid_loss:\n",
    "                best_valid_loss = valid_loss\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "            print(f'epoch {epoch:3d} | train {train_loss:5.5f} | valid {valid_loss:5.5f}')\n",
    "            scheduler.step()\n",
    "            graph.plot_loss(train_loss_list, valid_loss_list)\n",
    "        print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import data_processing as dp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def search_best_weights(model, test_motions, name):\n",
    "    model0 = copy.deepcopy(model)\n",
    "    model1 = copy.deepcopy(model)\n",
    "    model2 = copy.deepcopy(model)\n",
    "    model0.load_state_dict(torch.load(f\"model/{name}_0.pth\"))\n",
    "    model1.load_state_dict(torch.load(f\"model/{name}_1.pth\"))\n",
    "    model2.load_state_dict(torch.load(f\"model/{name}_2.pth\"))\n",
    "\n",
    "    # all motions\n",
    "    pred_data0 = []\n",
    "    pred_data1 = []\n",
    "    pred_data2 = []\n",
    "    lerp_data = []\n",
    "    for test_motion in test_motions:\n",
    "        if test_motion.data.shape[0] < input_window:\n",
    "            pred_data0.append(0.0)\n",
    "            pred_data1.append(0.0)\n",
    "            pred_data2.append(0.0)\n",
    "            lerp_data.append(0.0)\n",
    "            continue\n",
    "        source_data, target_data = dataset.make_predict_data(test_motion, interval)\n",
    "        source_data = dp.lost(source_data, interval)\n",
    "\n",
    "        pred_data0.append(pred.predict(model0, source_data, input_window, interval))\n",
    "        pred_data1.append(pred.predict(model1, source_data, input_window, interval))\n",
    "        pred_data2.append(pred.predict(model2, source_data, input_window, interval))\n",
    "        lerp_data.append(interpolation.linear_interpolate(source_data, interval))\n",
    "    \n",
    "    best_weights = np.zeros((21, 4))\n",
    "    min_loss = np.full((21), float(\"inf\"))\n",
    "    for marker in range(21):\n",
    "        for w0 in range(0, 11):\n",
    "            for w1 in range(0, 11 - w0):\n",
    "                for w2 in range(0, 11 - w0 - w1):\n",
    "                    w3 = 10 - w0 - w1 - w2\n",
    "                    pred_loss = 0\n",
    "                    for index, test_motion in enumerate(test_motions):\n",
    "                        if test_motion.data.shape[0] < input_window:\n",
    "                            continue\n",
    "                        source_data, target_data = dataset.make_predict_data(test_motion, interval)\n",
    "                        data0 = pred_data0[index][:, marker]\n",
    "                        data1 = pred_data1[index][:, marker]\n",
    "                        data2 = pred_data2[index][:, marker]\n",
    "                        data3 = lerp_data[index][:, marker]\n",
    "                        pred_data = (data0 * w0 + data1 * w1 + data2 * w2 + data3 * w3) / 10.0\n",
    "                        pred_loss += dp.calc_loss(pred_data, target_data[:, marker])\n",
    "                    if pred_loss < min_loss[marker]:\n",
    "                        min_loss[marker] = pred_loss\n",
    "                        best_weights[marker] = [w0, w1, w2, w3]\n",
    "    return best_weights\n",
    "\n",
    "def predict_with_weights(model, source_data, weights, markers, name):\n",
    "    model0 = copy.deepcopy(model)\n",
    "    model1 = copy.deepcopy(model)\n",
    "    model2 = copy.deepcopy(model)\n",
    "    model0.load_state_dict(torch.load(f\"model/{name}_0.pth\"))\n",
    "    model1.load_state_dict(torch.load(f\"model/{name}_1.pth\"))\n",
    "    model2.load_state_dict(torch.load(f\"model/{name}_2.pth\"))\n",
    "    \n",
    "    pred_data0 = pred.predict(model0, source_data, input_window, interval)\n",
    "    pred_data1 = pred.predict(model1, source_data, input_window, interval)\n",
    "    pred_data2 = pred.predict(model2, source_data, input_window, interval)\n",
    "    lerp_data = interpolation.linear_interpolate(source_data, interval)\n",
    "    \n",
    "    pred_data = np.zeros(source_data.shape)\n",
    "    for marker in range(21):\n",
    "        w0, w1, w2, w3 = weights[marker]\n",
    "        pred_data[:, marker] = (pred_data0[:, marker] * w0 + \n",
    "                                pred_data1[:, marker] * w1 + \n",
    "                                pred_data2[:, marker] * w2 + \n",
    "                                lerp_data[:, marker] * w3) / 10.0\n",
    "        # for axis in range(3):\n",
    "        #     plt.figure(figsize=(12, 8))\n",
    "        #     plt.plot(pred_data0[:, marker, axis], label=\"pred_data0\", c='r', linestyle='dashed')\n",
    "        #     plt.plot(pred_data1[:, marker, axis], label=\"pred_data1\", c='r', linestyle='dashed')\n",
    "        #     plt.plot(pred_data2[:, marker, axis], label=\"pred_data2\", c='r', linestyle='dashed')\n",
    "        #     plt.plot(lerp_data[:, marker, axis], label=\"lerp_data\", c='g', linestyle='dashed')\n",
    "        #     plt.plot(pred_data[:, marker, axis], label=\"pred_data\", c='b')\n",
    "        #     plt.legend()\n",
    "        #     # plt.savefig(f\"graph/{name}_{marker}_{axis}.png\")\n",
    "        #     plt.close()\n",
    "\n",
    "    return pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== 2_45_run ======\n",
      "train_motions: 20\n",
      "valid_motions: 3\n",
      "weights: [[7. 0. 0. 3.]\n",
      " [6. 0. 0. 4.]\n",
      " [6. 0. 0. 4.]\n",
      " [4. 0. 2. 4.]\n",
      " [2. 1. 4. 3.]\n",
      " [5. 0. 1. 4.]\n",
      " [6. 0. 0. 4.]\n",
      " [7. 1. 2. 0.]\n",
      " [4. 0. 5. 1.]\n",
      " [4. 0. 2. 4.]\n",
      " [4. 0. 2. 4.]\n",
      " [5. 1. 3. 1.]\n",
      " [4. 2. 4. 0.]\n",
      " [7. 0. 0. 3.]\n",
      " [5. 0. 3. 2.]\n",
      " [5. 2. 2. 1.]\n",
      " [6. 2. 1. 1.]\n",
      " [7. 0. 0. 3.]\n",
      " [6. 1. 1. 2.]\n",
      " [4. 2. 2. 2.]\n",
      " [4. 1. 3. 2.]]\n",
      "motion: 082 (141, 21, 3)\n",
      "\tlerp loss: 88.64927\n",
      "\tpred loss: 8.68404\n",
      "motion: 083 (141, 21, 3)\n",
      "\tlerp loss: 81.93764\n",
      "\tpred loss: 21.25569\n",
      "motion: 084 (133, 21, 3)\n",
      "\tlerp loss: 76.30894\n",
      "\tpred loss: 20.29217\n",
      "total_loss: 50.23189692463438\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "test\n",
    "\"\"\"\n",
    "\n",
    "all_lerp_motions = []\n",
    "all_pred_motions = []\n",
    "for name in model_settings:\n",
    "    interval, sections, markers, motion_list, rates, filter_setting = model_settings[name]\n",
    "    input_window = interval * sections + 1\n",
    "    \n",
    "    model = TransMotion(interval).to(device).double()\n",
    "\n",
    "    print(f\"====== {name} ======\")\n",
    "    _, valid_motions = dataset.get_train_valid(motion_list)\n",
    "\n",
    "    # TODO: motion list\n",
    "    weights = search_best_weights(model, valid_motions, name)\n",
    "    print(f\"weights: {weights}\")\n",
    "    # === predict ===\n",
    "    lerp_motions = copy.deepcopy(valid_motions)\n",
    "    pred_motions = copy.deepcopy(valid_motions)\n",
    "    total_loss = 0.0\n",
    "    for index, valid_motion in enumerate(valid_motions):\n",
    "        if valid_motion.data.shape[0] < input_window:\n",
    "            continue\n",
    "        source_data, target_data = dataset.make_predict_data(valid_motion, interval)\n",
    "        source_data = dp.lost(source_data, interval)\n",
    "\n",
    "        print(\"motion:\", valid_motion.name, valid_motion.data.shape)\n",
    "\n",
    "        lerp_data = interpolation.linear_interpolate(source_data, interval)\n",
    "        pred_data = predict_with_weights(model, source_data, weights, markers, name)\n",
    "        \n",
    "        lerp_loss = dp.calc_loss(lerp_data[:, markers], target_data[:, markers])\n",
    "        pred_loss = dp.calc_loss(pred_data[:, markers], target_data[:, markers])\n",
    "\n",
    "        # for marker in range(21):\n",
    "        #     for axis in range(3):\n",
    "        #         plt.figure(figsize=(12, 8))\n",
    "        #         plt.plot(lerp_data[:, marker, axis], label=\"lerp_data\", c='g', linestyle='dashed')\n",
    "        #         plt.plot(pred_data[:, marker, axis], label=\"pred_data\", c='r')\n",
    "        #         plt.plot(target_data[:, marker, axis], label=\"target_data\", c='b')\n",
    "        #         plt.legend()\n",
    "        #         plt.show()\n",
    "        #         plt.close()\n",
    "\n",
    "\n",
    "        print(f'\\tlerp loss: {lerp_loss:5.5f}')\n",
    "        print(f'\\tpred loss: {pred_loss:5.5f}')\n",
    "        total_loss += pred_loss\n",
    "\n",
    "        lerp_motions[index].data = lerp_data\n",
    "        pred_motions[index].data = pred_data\n",
    "\n",
    "    print(\"total_loss:\", total_loss)\n",
    "    all_lerp_motions = all_lerp_motions + lerp_motions\n",
    "    all_pred_motions = all_pred_motions + pred_motions\n",
    "\n",
    "csvio.write_csv(\"output_data/test_lerp.csv\", headers, all_lerp_motions)\n",
    "csvio.write_csv(\"output_data/test_pred.csv\", headers, all_pred_motions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "hard\n",
    "\"\"\"\n",
    "\n",
    "motions, header = csvio.load_data('./input_data/test/test_hard.csv')\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "methods = {\n",
    "    \"013\": \"0_45_bow\",     # bow\n",
    "    \"022\": \"1_45_wavr\",     # wav right\n",
    "    \"032\": \"1_45_wavb\",     # wav both\n",
    "    \"049\": \"2_45_run\", # run\n",
    "    # \"059\": \"lerp\",     # frt\n",
    "    \"059\": \"3_45_frt\", # frt\n",
    "    \"078\": \"2_45_run\", # run\n",
    "    \"098\": \"4_45_wlk\", # walk\n",
    "    \"101\": \"4_45_wlk\", # walk\n",
    "    \"113\": \"4_45_wlk\", # walk\n",
    "    \"134\": \"6_45_rgt\", # right\n",
    "}\n",
    "\n",
    "for motion in motions:\n",
    "    source_data = motion.data\n",
    "    if motion.name != \"059\":\n",
    "        continue\n",
    "\n",
    "    method = methods[motion.name]\n",
    "    print(f\"motion: {motion.name} {method} {source_data.shape}\")\n",
    "\n",
    "\n",
    "    if method == \"lerp\":\n",
    "        output_data = interpolation.linear_interpolate(source_data, interval)\n",
    "    elif method == \"quad\":\n",
    "        output_data = interpolation.quadratic_interpolate(source_data, interval)\n",
    "    else:\n",
    "        interval, sections, markers, motion_list, rates, filter_setting = model_settings[method]\n",
    "        input_window = interval * sections + 1\n",
    "        d_input = len(markers) * 3\n",
    "        model = TransMotion(interval).to(device).double()\n",
    "        _, valid_motions = dataset.get_train_valid(motion_list)\n",
    "\n",
    "        weights = search_best_weights(model, valid_motions, method)\n",
    "        output_data = predict_with_weights(model, source_data, weights, markers, method)\n",
    "\n",
    "        for marker in range(21):\n",
    "            for axis in range(3):\n",
    "                plt.figure(figsize=(12, 8))\n",
    "                plt.plot(source_data[:, marker, axis], label=\"lerp_data\", c='g', linestyle='dashed')\n",
    "                plt.plot(output_data[:, marker, axis], label=\"pred_data\", c='r')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "                plt.close()\n",
    "        \n",
    "\n",
    "    motion.data = output_data\n",
    "\n",
    "csvio.write_csv(\"./output_data/test_hard.csv\", header, motions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "normal\n",
    "\"\"\"\n",
    "\n",
    "motions, header = csvio.load_data('./input_data/test/test_normal.csv')\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "methods = {\n",
    "    \"005\": \"quad\",  # bow\n",
    "    # \"028\": \"lerp\",  # wave_hands\n",
    "    \"028\": \"1_15_wavr\",  # wave_hands\n",
    "    \"036\": \"3_15_frt\",  # front_hands\n",
    "    \"067\": \"3_15_frt\",  # front_hands\n",
    "    \"079\": \"2_15_run\", # run\n",
    "    \"085\": \"4_15_wlk\", # walk\n",
    "    \"122\": \"5_15_bck\", # back\n",
    "    \"130\": \"6_15_rgt\", # right\n",
    "    \"144\": \"7_15_lft\", # left\n",
    "    \"155\": \"7_15_lft\", # left\n",
    "}\n",
    "\n",
    "\n",
    "for motion in motions:\n",
    "    source_data = motion.data\n",
    "\n",
    "    method = methods[motion.name]\n",
    "    print(f\"motion: {motion.name} {method} {source_data.shape}\")\n",
    "\n",
    "    if method == \"lerp\":\n",
    "        output_data = interpolation.linear_interpolate(source_data, interval)\n",
    "    elif method == \"quad\":\n",
    "        output_data = interpolation.quadratic_interpolate(source_data, interval)\n",
    "    else:\n",
    "        interval, sections, markers, motion_list, rates, filter_setting = model_settings[method]\n",
    "        input_window = interval * sections + 1\n",
    "        d_input = len(markers) * 3\n",
    "        model = TransMotion(interval, d_input=d_input).to(device).double()\n",
    "        _, valid_motions = dataset.get_train_valid(motion_list)\n",
    "\n",
    "        weights = search_best_weights(model, valid_motions, markers, method)\n",
    "        output_data = predict_with_weights(model, source_data, weights, markers, method)\n",
    "\n",
    "    motion.data = output_data\n",
    "\n",
    "csvio.write_csv(\"./output_data/test_normal.csv\", header, motions)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ab13c149dc041da72c7c2431195840fc8a82bda9ec674136a754290441306fa2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('ds': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
